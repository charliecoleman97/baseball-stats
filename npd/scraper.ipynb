{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting with scraping all the player stats for the 2022 Orix Buffalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests_html import HTMLSession\n",
    "import pandas as pd\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_league_url(base_url: str, league: str) -> str:\n",
    "    \"\"\"\n",
    "    Finds the league page url \n",
    "\n",
    "    :param base_url: url for the baseball reference homepage\n",
    "    :param league: the name of the league we want the url for\n",
    "    :return league_url: full league url\n",
    "    \"\"\"\n",
    "    leagues_url = base_url + '/register/'\n",
    "\n",
    "    s = HTMLSession()\n",
    "    page = s.get(leagues_url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    league_link = soup.find('a', text=league)['href']\n",
    "\n",
    "    return base_url + league_link\n",
    "\n",
    "\n",
    "def get_team_urls(base_url: str, league_url: str) -> dict:\n",
    "    \"\"\"\n",
    "    Finds the urls for each team page and saves to a dictionary \n",
    "\n",
    "    :param base_url: url for the baseball reference homepage\n",
    "    :param league_url: full url for the league page\n",
    "    :return team_dict: dictionary with team name as the key and \n",
    "                        team page url as the value \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # TO DO: Add a year variable rather than hard code 2022\n",
    "\n",
    "    s = HTMLSession()\n",
    "    page = s.get(league_url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    # Find start and end links so we can get all the links in between\n",
    "    start_link = soup.find_all('a', text=\"2022\")[-2]\n",
    "    end_link = soup.find_all('a', text='2021')[-2]\n",
    "\n",
    "    team_dict = {}\n",
    "    current_link = start_link.find_next('a') \n",
    "    while current_link != end_link:\n",
    "        team_name = current_link.text  # loop through links until the ending link is reached\n",
    "        full_url = base_url + current_link['href']\n",
    "        team_dict[team_name] = full_url\n",
    "        current_link = current_link.find_next('a')\n",
    "    \n",
    "    return team_dict\n",
    "\n",
    "\n",
    "def get_stats_table(url: str, id: str) -> pd.DataFrame:  \n",
    "    \"\"\"\n",
    "    Scrapes the pitching and batting table depending on the ID provided\n",
    "    \n",
    "    :param url: full team url \n",
    "    :param id: used to determine which table to scrape (batting or pitching)\n",
    "    :returns stats_df: pandas dataframe of either the team batting or pitching table\n",
    "    \"\"\"\n",
    "    \n",
    "    s = HTMLSession()\n",
    "    page = s.get(url)\n",
    "    stats_div = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    # Pitching table is in a comment for some reason so have to do some \n",
    "    # cleaning before converting to DF\n",
    "    if id == \"team_pitching\":\n",
    "        s = str(stats_div.find(\"div\", id=\"all_team_pitching\"))\n",
    "        start_len, end_len = s.find('<table'), s.rfind('</table>')\n",
    "        cleaned_page = s[start_len:end_len + len('</table>')]\n",
    "        stats_div = BeautifulSoup(cleaned_page, \"html.parser\")  \n",
    "        \n",
    "    stats_table = stats_div.find(\"table\", id=id)\n",
    "\n",
    "    stats_df = pd.DataFrame()\n",
    "    for row in stats_table.tbody.find_all(\"tr\"):\n",
    "        columns = row.find_all(\"td\")\n",
    "        \n",
    "        if(columns != []):\n",
    "            stats_dict = {}\n",
    "            for i in range(0, len(columns)):\n",
    "                stats_dict[columns[i][\"data-stat\"]] = columns[i].text.strip()\n",
    "            stats_df = stats_df.append(stats_dict, ignore_index=True)\n",
    "\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.baseball-reference.com\" \n",
    "league = \"Japan Pacific League\"\n",
    "\n",
    "jpl_url = get_league_url(base_url, \"Japan Pacific League\")\n",
    "jcl_url = get_league_url(base_url, \"Japan Central League\")\n",
    "\n",
    "pacfic_teams_dict = get_team_urls(base_url, jpl_url)\n",
    "\n",
    "central_teams_dict = get_team_urls(base_url, jcl_url)\n",
    "\n",
    "batting_stats = get_stats_table(pacfic_teams_dict.get(\"Fukuoka Softbank Hawks\"), \"team_batting\")\n",
    "pitching_stats = get_stats_table(pacfic_teams_dict.get(\"Fukuoka Softbank Hawks\"), \"team_pitching\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed17212fccccbb12e83c24386c5ff03117b85ebaf90e831a0bd1be0b92eeb92c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
